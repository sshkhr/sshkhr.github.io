---
title: "From Strings to Things: Knowledge-enabled VQA Model that can Read and Reason"
collection: publications
permalink: /publication/2019-11-02-iccv-tkvqa-04
excerpt: 'We released the first dataset for Visual Question Answering (VQA) that requires traversing an external knowledge-graph as well as understanding scene-text through Optical Character Recognition (OCR). We also proposed a Graph-RNN based approach for VQA with external knowledge and demonstrated state-of-the-art results.'
date: 2019-11-02
venue: 'International Conference on Computer Vision'
paperurl: 'http://openaccess.thecvf.com/content_ICCV_2019/papers/Singh_From_Strings_to_Things_Knowledge-Enabled_VQA_Model_That_Can_Read_ICCV_2019_paper.pdf'
citation: ''
authors: 'Ajeet Kumar Singh, Anand Mishra, Shashank Shekhar, Anirban Chakraborty'
image: 'images/tkvqa.png' 
page: 'https://textkvqa.github.io/'

---
